{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = (torch.rand(1,10,10)*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = inp.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4, 1, 4, 5, 3, 0, 5, 3, 9, 4],\n",
       "         [3, 8, 5, 9, 9, 3, 0, 2, 4, 8],\n",
       "         [8, 5, 2, 6, 1, 9, 8, 7, 5, 0],\n",
       "         [2, 5, 1, 3, 1, 4, 6, 5, 6, 5],\n",
       "         [9, 0, 8, 6, 6, 6, 5, 1, 9, 8],\n",
       "         [3, 9, 2, 3, 4, 7, 7, 2, 3, 5],\n",
       "         [8, 3, 8, 3, 5, 2, 1, 3, 4, 4],\n",
       "         [2, 7, 6, 5, 8, 5, 2, 5, 0, 7],\n",
       "         [9, 1, 1, 3, 3, 3, 7, 6, 0, 6],\n",
       "         [3, 7, 3, 4, 4, 3, 0, 7, 4, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = nn.MaxPool2d(2, stride=2, return_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpool = nn.MaxUnpool2d(2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([[[[ 1.,  2.,  3.,  4.],\n",
    "                            [ 5.,  6.,  7.,  8.],\n",
    "                            [ 9., 10., 11., 12.],\n",
    "                            [13., 14., 15., 16.]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, indices = pool(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[8, 9, 9, 5, 9],\n",
       "         [8, 6, 9, 8, 6],\n",
       "         [9, 8, 7, 7, 9],\n",
       "         [8, 8, 8, 5, 7],\n",
       "         [9, 4, 4, 7, 6]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4, 1, 4, 5, 3, 0, 5, 3, 9, 4],\n",
       "         [3, 8, 5, 9, 9, 3, 0, 2, 4, 8],\n",
       "         [8, 5, 2, 6, 1, 9, 8, 7, 5, 0],\n",
       "         [2, 5, 1, 3, 1, 4, 6, 5, 6, 5],\n",
       "         [9, 0, 8, 6, 6, 6, 5, 1, 9, 8],\n",
       "         [3, 9, 2, 3, 4, 7, 7, 2, 3, 5],\n",
       "         [8, 3, 8, 3, 5, 2, 1, 3, 4, 4],\n",
       "         [2, 7, 6, 5, 8, 5, 2, 5, 0, 7],\n",
       "         [9, 1, 1, 3, 3, 3, 7, 6, 0, 6],\n",
       "         [3, 7, 3, 4, 4, 3, 0, 7, 4, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[11, 13, 14,  6,  8],\n",
       "         [20, 23, 25, 26, 38],\n",
       "         [40, 42, 55, 56, 48],\n",
       "         [60, 62, 74, 77, 79],\n",
       "         [80, 93, 94, 86, 89]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 5., 0., 9., 0.],\n",
       "         [0., 8., 0., 9., 9., 0., 0., 0., 0., 0.],\n",
       "         [8., 0., 0., 6., 0., 9., 8., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 6., 0.],\n",
       "         [9., 0., 8., 0., 0., 0., 0., 0., 9., 0.],\n",
       "         [0., 0., 0., 0., 0., 7., 7., 0., 0., 0.],\n",
       "         [8., 0., 8., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 8., 0., 0., 5., 0., 7.],\n",
       "         [9., 0., 0., 0., 0., 0., 7., 0., 0., 6.],\n",
       "         [0., 0., 0., 4., 4., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpool(output.float(), indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegNetLite(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_sizes=[3, 3, 3, 3], down_filter_sizes=[32, 64, 128, 256],\n",
    "            up_filter_sizes=[128, 64, 32, 32], conv_paddings=[1, 1, 1, 1],\n",
    "            pooling_kernel_sizes=[2, 2, 2, 2], pooling_strides=[2, 2, 2, 2], **kwargs):\n",
    "        \"\"\"Initialize SegNet Module\n",
    "\n",
    "        Args:\n",
    "            kernel_sizes (list of ints): kernel sizes for each convolutional layer in downsample/upsample path.\n",
    "            down_filter_sizes (list of ints): number of filters (out channels) of each convolutional layer in the downsample path.\n",
    "            up_filter_sizes (list of ints): number of filters (out channels) of each convolutional layer in the upsample path.\n",
    "            conv_paddings (list of ints): paddings for each convolutional layer in downsample/upsample path.\n",
    "            pooling_kernel_sizes (list of ints): kernel sizes for each max-pooling layer and its max-unpooling layer.\n",
    "            pooling_strides (list of ints): strides for each max-pooling layer and its max-unpooling layer.\n",
    "        \"\"\"\n",
    "        super(SegNetLite, self).__init__()\n",
    "        self.num_down_layers = len(kernel_sizes)\n",
    "        self.num_up_layers = len(kernel_sizes)\n",
    "\n",
    "        input_size = 3 # initial number of input channels\n",
    "        # Construct downsampling layers.\n",
    "        # As mentioned in the assignment, blocks of the downsampling path should have the\n",
    "        # following output dimension (igoring batch dimension):\n",
    "        # 3 x 64 x 64 (input) -> 32 x 32 x 32 -> 64 x 16 x 16 -> 128 x 8 x 8 -> 256 x 4 x 4\n",
    "        # each block should consist of: Conv2d->BatchNorm2d->ReLU->MaxPool2d\n",
    "        layers_conv_down = [\n",
    "            nn.Conv2d(in_channels=inp_ch, out_channels=fs, kernel_size=ks, padding=pad)\n",
    "            for inp_ch, fs, ks, pad in zip([input_size]+down_filter_sizes[:-1], down_filter_sizes, kernel_sizes, conv_paddings) \n",
    "        ]\n",
    "        layers_bn_down = [nn.BatchNorm2d(fs) for fs in down_filter_sizes]\n",
    "        layers_pooling = [nn.MaxPool2d(kernel_size=pks, stride=ps, return_indices=True) for pks, ps in zip(pooling_kernel_sizes, pooling_strides)]\n",
    "\n",
    "        # Convert Python list to nn.ModuleList, so that PyTorch's autograd\n",
    "        # package can track gradients and update parameters of these layers\n",
    "        self.layers_conv_down = nn.ModuleList(layers_conv_down)\n",
    "        self.layers_bn_down = nn.ModuleList(layers_bn_down)\n",
    "        self.layers_pooling = nn.ModuleList(layers_pooling)\n",
    "\n",
    "        # Construct upsampling layers\n",
    "        # As mentioned in the assignment, blocks of the upsampling path should have the\n",
    "        # following output dimension (igoring batch dimension):\n",
    "        # 256 x 4 x 4 (input) -> 128 x 8 x 8 -> 64 x 16 x 16 -> 32 x 32 x 32 -> 32 x 64 x 64\n",
    "        # each block should consist of: MaxUnpool2d->Conv2d->BatchNorm2d->ReLU\n",
    "        layers_conv_up = [\n",
    "            nn.Conv2d(in_channels=inp_ch, out_channels=fs, kernel_size=ks, padding=pad)\n",
    "            for inp_ch, fs, ks, pad in zip(list(reversed(down_filter_sizes)), up_filter_sizes, kernel_sizes, conv_paddings) \n",
    "        ]\n",
    "        layers_bn_up = [nn.BatchNorm2d(fs) for fs in up_filter_sizes]\n",
    "        layers_unpooling = [nn.MaxUnpool2d(kernel_size=pks, stride=ps) for pks, ps in zip(pooling_kernel_sizes, pooling_strides)]\n",
    "\n",
    "        # Convert Python list to nn.ModuleList, so that PyTorch's autograd\n",
    "        # can track gradients and update parameters of these layers\n",
    "        self.layers_conv_up = nn.ModuleList(layers_conv_up)\n",
    "        self.layers_bn_up = nn.ModuleList(layers_bn_up)\n",
    "        self.layers_unpooling = nn.ModuleList(layers_unpooling)\n",
    "\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "        # Implement a final 1x1 convolution to to get the logits of 11 classes (background + 10 digits)\n",
    "        self.segconv = nn.Conv2d(in_channels=up_filter_sizes[-1], out_channels=11, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        indices_list = [] # keep track of indices for unmaxpooling\n",
    "        \n",
    "        # downsample\n",
    "        for conv, bn, maxpool in zip(self.layers_conv_down, self.layers_bn_down, self.layers_pooling):\n",
    "            x = conv(x)\n",
    "            x = bn(x)\n",
    "            x = self.relu(x)\n",
    "            x, indices = maxpool(x)\n",
    "            indices_list.append(indices)\n",
    "            \n",
    "        indices_list = list(reversed(indices_list))\n",
    "        \n",
    "        # upsample\n",
    "        for conv, bn, unmaxpool, indices in zip(self.layers_conv_up, self.layers_bn_up, self.layers_unpooling, indices_list):\n",
    "            x = unmaxpool(x, indices)\n",
    "            x = conv(x)\n",
    "            x = bn(x)\n",
    "            x = self.relu(x)\n",
    "            \n",
    "        # final conv => 11 class segm\n",
    "        x = self.segconv(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_down_layers = len(kernel_sizes)\n",
    "num_up_layers = len(kernel_sizes)\n",
    "\n",
    "input_size = 3 # initial number of input channels\n",
    "# Construct downsampling layers.\n",
    "# As mentioned in the assignment, blocks of the downsampling path should have the\n",
    "# following output dimension (igoring batch dimension):\n",
    "# 3 x 64 x 64 (input) -> 32 x 32 x 32 -> 64 x 16 x 16 -> 128 x 8 x 8 -> 256 x 4 x 4\n",
    "# each block should consist of: Conv2d->BatchNorm2d->ReLU->MaxPool2d\n",
    "layers_conv_down = [\n",
    "    nn.Conv2d(in_channels=inp_ch, out_channels=fs, kernel_size=ks, padding=pad)\n",
    "    for inp_ch, fs, ks, pad in zip([input_size]+down_filter_sizes[:-1], down_filter_sizes, kernel_sizes, conv_paddings) \n",
    "]\n",
    "layers_bn_down = [nn.BatchNorm2d(fs) for fs in down_filter_sizes]\n",
    "layers_pooling = [nn.MaxPool2d(kernel_size=pks, stride=ps, return_indices=True) for pks, ps in zip(pooling_kernel_sizes, pooling_strides)]\n",
    "\n",
    "# Convert Python list to nn.ModuleList, so that PyTorch's autograd\n",
    "# package can track gradients and update parameters of these layers\n",
    "layers_conv_down = nn.ModuleList(layers_conv_down)\n",
    "layers_bn_down = nn.ModuleList(layers_bn_down)\n",
    "layers_pooling = nn.ModuleList(layers_pooling)\n",
    "\n",
    "# Construct upsampling layers\n",
    "# As mentioned in the assignment, blocks of the upsampling path should have the\n",
    "# following output dimension (igoring batch dimension):\n",
    "# 256 x 4 x 4 (input) -> 128 x 8 x 8 -> 64 x 16 x 16 -> 32 x 32 x 32 -> 32 x 64 x 64\n",
    "# each block should consist of: MaxUnpool2d->Conv2d->BatchNorm2d->ReLU\n",
    "layers_conv_up = [\n",
    "    nn.Conv2d(in_channels=inp_ch, out_channels=fs, kernel_size=ks, padding=pad)\n",
    "    for inp_ch, fs, ks, pad in zip(list(reversed(down_filter_sizes)), up_filter_sizes, kernel_sizes, conv_paddings) \n",
    "]\n",
    "layers_bn_up = [nn.BatchNorm2d(fs) for fs in up_filter_sizes]\n",
    "layers_unpooling = [nn.MaxUnpool2d(kernel_size=pks, stride=ps) for pks, ps in zip(pooling_kernel_sizes, pooling_strides)]\n",
    "\n",
    "# Convert Python list to nn.ModuleList, so that PyTorch's autograd\n",
    "# can track gradients and update parameters of these layers\n",
    "layers_conv_up = nn.ModuleList(layers_conv_up)\n",
    "layers_bn_up = nn.ModuleList(layers_bn_up)\n",
    "layers_unpooling = nn.ModuleList(layers_unpooling)\n",
    "\n",
    "relu = nn.ReLU(True)\n",
    "\n",
    "# Implement a final 1x1 convolution to to get the logits of 11 classes (background + 10 digits)\n",
    "segconv = nn.Conv2d(in_channels=up_filter_sizes[-1], out_channels=11, kernel_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 64, 64])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 64, 64])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [256, 128, 3, 3], expected input[16, 3, 64, 64] to have 128 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ex4/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ex4/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ex4/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ex4/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [256, 128, 3, 3], expected input[16, 3, 64, 64] to have 128 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "conv(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 64, 64])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(16, 3, 64, 64)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_list = [] # keep track of indices for unmaxpooling\n",
    "# downsample\n",
    "for conv, bn, maxpool in zip(layers_conv_down, layers_bn_down, layers_pooling):\n",
    "    x = conv(x)\n",
    "    x = bn(x)\n",
    "    x = relu(x)\n",
    "    x, indices = maxpool(x)\n",
    "    indices_list.append(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256, 4, 4])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_conv_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample\n",
    "for conv, bn, unmaxpool, indices in zip(layers_conv_up, layers_bn_up, layers_unpooling, list(reversed(indices_list))):\n",
    "    x = unmaxpool(x, indices)\n",
    "    x = conv(x)\n",
    "    x = bn(x)\n",
    "    x = relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 64, 64])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final conv => 11 class segm\n",
    "x = segconv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 11, 64, 64])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(16,32,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 11, 64, 64])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Conv2d(in_channels=up_filter_sizes[-1], out_channels=11, kernel_size=1)(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seg_net(**kwargs):\n",
    "\n",
    "    model = SegNetLite(**kwargs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 64, 64])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(32, 3,64,64)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes=[3, 3, 3, 3]\n",
    "down_filter_sizes=[32, 64, 128, 256]\n",
    "up_filter_sizes=[128, 64, 32, 32]\n",
    "conv_paddings=[1, 1, 1, 1]\n",
    "pooling_kernel_sizes=[2, 2, 2, 2]\n",
    "pooling_strides=[2, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 64, 64])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = nn.Conv2d(in_channels=input_size, out_channels=down_filter_sizes[0], kernel_size=kernel_sizes[0], padding=kernel_sizes[0]//2)(X)\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "unpool = nn.MaxUnpool2d(2, stride=2)\n",
    "input = torch.randn(16, 3, 64, 64)\n",
    "output, indices = pool(input)\n",
    "qq = unpool(output, indices)\n",
    "qq.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, indices = pool(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 32, 32])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[   1,    2,    4,  ...,   58,   60,  126],\n",
       "          [ 129,  130,  196,  ...,  186,  188,  254],\n",
       "          [ 256,  258,  325,  ...,  379,  381,  382],\n",
       "          ...,\n",
       "          [3777, 3714, 3717,  ..., 3770, 3836, 3774],\n",
       "          [3905, 3906, 3908,  ..., 3899, 3900, 3903],\n",
       "          [4033, 3970, 3973,  ..., 4091, 4029, 4030]],\n",
       "\n",
       "         [[   0,   67,    4,  ...,   58,   61,   63],\n",
       "          [ 128,  195,  197,  ...,  250,  189,  254],\n",
       "          [ 257,  259,  324,  ...,  379,  380,  382],\n",
       "          ...,\n",
       "          [3712, 3715, 3716,  ..., 3770, 3772, 3774],\n",
       "          [3905, 3842, 3908,  ..., 3962, 3901, 3903],\n",
       "          [3968, 3971, 4036,  ..., 4090, 4028, 4094]],\n",
       "\n",
       "         [[   0,   66,    5,  ...,  123,  124,  126],\n",
       "          [ 128,  195,  132,  ...,  186,  252,  254],\n",
       "          [ 257,  258,  260,  ...,  315,  380,  319],\n",
       "          ...,\n",
       "          [3776, 3778, 3717,  ..., 3770, 3836, 3839],\n",
       "          [3840, 3906, 3845,  ..., 3963, 3901, 3903],\n",
       "          [4033, 4034, 4037,  ..., 4091, 4028, 4031]]],\n",
       "\n",
       "\n",
       "        [[[   1,    2,    4,  ...,   59,   60,   63],\n",
       "          [ 128,  131,  132,  ...,  251,  189,  254],\n",
       "          [ 256,  322,  261,  ...,  315,  317,  319],\n",
       "          ...,\n",
       "          [3713, 3778, 3781,  ..., 3770, 3773, 3775],\n",
       "          [3904, 3843, 3909,  ..., 3899, 3900, 3967],\n",
       "          [4033, 4034, 3973,  ..., 4090, 4092, 4095]],\n",
       "\n",
       "         [[   1,   67,   69,  ...,   58,  125,  127],\n",
       "          [ 193,  131,  197,  ...,  186,  188,  190],\n",
       "          [ 256,  322,  260,  ...,  314,  317,  382],\n",
       "          ...,\n",
       "          [3713, 3714, 3780,  ..., 3770, 3836, 3838],\n",
       "          [3840, 3907, 3845,  ..., 3899, 3900, 3966],\n",
       "          [3968, 3970, 3972,  ..., 4090, 4092, 4030]],\n",
       "\n",
       "         [[   1,   67,    4,  ...,  122,   61,   62],\n",
       "          [ 193,  130,  196,  ...,  186,  253,  255],\n",
       "          [ 257,  258,  325,  ...,  379,  317,  318],\n",
       "          ...,\n",
       "          [3776, 3715, 3780,  ..., 3835, 3772, 3774],\n",
       "          [3840, 3907, 3844,  ..., 3963, 3964, 3902],\n",
       "          [4032, 4035, 3973,  ..., 4090, 4092, 4094]]],\n",
       "\n",
       "\n",
       "        [[[   0,   67,    5,  ...,   59,   60,   62],\n",
       "          [ 192,  194,  196,  ...,  187,  188,  191],\n",
       "          [ 257,  259,  261,  ...,  315,  317,  319],\n",
       "          ...,\n",
       "          [3713, 3714, 3781,  ..., 3834, 3836, 3775],\n",
       "          [3904, 3906, 3908,  ..., 3962, 3965, 3902],\n",
       "          [3969, 3971, 3972,  ..., 4090, 4029, 4094]],\n",
       "\n",
       "         [[   0,    2,    5,  ...,   59,  125,  127],\n",
       "          [ 129,  194,  133,  ...,  251,  188,  190],\n",
       "          [ 320,  323,  324,  ...,  315,  317,  383],\n",
       "          ...,\n",
       "          [3777, 3714, 3781,  ..., 3834, 3773, 3775],\n",
       "          [3840, 3907, 3908,  ..., 3962, 3900, 3902],\n",
       "          [4032, 3970, 4037,  ..., 4027, 4093, 4030]],\n",
       "\n",
       "         [[  64,   66,   69,  ...,   59,   61,  127],\n",
       "          [ 128,  131,  197,  ...,  251,  252,  255],\n",
       "          [ 256,  258,  260,  ...,  378,  316,  318],\n",
       "          ...,\n",
       "          [3712, 3778, 3781,  ..., 3834, 3773, 3838],\n",
       "          [3905, 3843, 3845,  ..., 3962, 3964, 3966],\n",
       "          [4032, 4035, 3972,  ..., 4091, 4029, 4031]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[  64,    2,   69,  ...,   59,  125,  126],\n",
       "          [ 193,  131,  197,  ...,  186,  252,  254],\n",
       "          [ 257,  323,  260,  ...,  379,  316,  318],\n",
       "          ...,\n",
       "          [3776, 3714, 3780,  ..., 3771, 3773, 3774],\n",
       "          [3841, 3907, 3908,  ..., 3963, 3965, 3966],\n",
       "          [3969, 3971, 3973,  ..., 4027, 4092, 4095]],\n",
       "\n",
       "         [[  64,    3,    4,  ...,  123,  124,   62],\n",
       "          [ 129,  131,  133,  ...,  250,  253,  191],\n",
       "          [ 257,  259,  325,  ...,  379,  381,  382],\n",
       "          ...,\n",
       "          [3777, 3779, 3781,  ..., 3835, 3772, 3774],\n",
       "          [3904, 3906, 3908,  ..., 3898, 3901, 3902],\n",
       "          [4032, 4034, 4037,  ..., 4026, 4092, 4094]],\n",
       "\n",
       "         [[   0,   67,    5,  ...,  123,  124,  127],\n",
       "          [ 193,  195,  197,  ...,  250,  252,  190],\n",
       "          [ 257,  322,  324,  ...,  378,  380,  319],\n",
       "          ...,\n",
       "          [3712, 3714, 3781,  ..., 3835, 3773, 3774],\n",
       "          [3840, 3842, 3909,  ..., 3963, 3900, 3966],\n",
       "          [4032, 4035, 3972,  ..., 4090, 4029, 4094]]],\n",
       "\n",
       "\n",
       "        [[[   0,    2,   69,  ...,   58,   61,  126],\n",
       "          [ 128,  130,  197,  ...,  250,  253,  255],\n",
       "          [ 257,  322,  324,  ...,  378,  380,  382],\n",
       "          ...,\n",
       "          [3777, 3715, 3781,  ..., 3771, 3773, 3838],\n",
       "          [3840, 3906, 3908,  ..., 3899, 3900, 3967],\n",
       "          [4033, 3970, 3973,  ..., 4091, 4028, 4031]],\n",
       "\n",
       "         [[  64,   66,   68,  ...,  123,   60,  126],\n",
       "          [ 192,  195,  133,  ...,  187,  188,  190],\n",
       "          [ 256,  259,  260,  ...,  378,  316,  318],\n",
       "          ...,\n",
       "          [3713, 3714, 3780,  ..., 3835, 3772, 3839],\n",
       "          [3841, 3843, 3844,  ..., 3963, 3900, 3966],\n",
       "          [4033, 4035, 3972,  ..., 4026, 4093, 4031]],\n",
       "\n",
       "         [[  64,   66,    4,  ...,  123,   60,  127],\n",
       "          [ 128,  131,  133,  ...,  250,  252,  254],\n",
       "          [ 257,  259,  324,  ...,  378,  381,  383],\n",
       "          ...,\n",
       "          [3712, 3715, 3781,  ..., 3770, 3773, 3775],\n",
       "          [3905, 3906, 3845,  ..., 3963, 3964, 3903],\n",
       "          [3969, 3970, 3972,  ..., 4091, 4028, 4031]]],\n",
       "\n",
       "\n",
       "        [[[   1,    2,    5,  ...,   59,  125,  127],\n",
       "          [ 192,  194,  132,  ...,  186,  188,  255],\n",
       "          [ 320,  258,  261,  ...,  378,  381,  319],\n",
       "          ...,\n",
       "          [3777, 3778, 3716,  ..., 3834, 3773, 3838],\n",
       "          [3905, 3906, 3844,  ..., 3898, 3965, 3902],\n",
       "          [4032, 4035, 3973,  ..., 4026, 4028, 4031]],\n",
       "\n",
       "         [[  65,    2,    5,  ...,  122,  124,   62],\n",
       "          [ 129,  130,  133,  ...,  251,  188,  254],\n",
       "          [ 321,  258,  261,  ...,  314,  381,  382],\n",
       "          ...,\n",
       "          [3777, 3779, 3717,  ..., 3835, 3772, 3775],\n",
       "          [3905, 3907, 3909,  ..., 3963, 3964, 3966],\n",
       "          [4032, 3970, 4036,  ..., 4091, 4028, 4030]],\n",
       "\n",
       "         [[   0,   67,   68,  ...,  123,   60,  126],\n",
       "          [ 128,  194,  133,  ...,  186,  253,  255],\n",
       "          [ 256,  258,  260,  ...,  314,  317,  382],\n",
       "          ...,\n",
       "          [3713, 3779, 3717,  ..., 3771, 3836, 3839],\n",
       "          [3904, 3843, 3844,  ..., 3963, 3901, 3902],\n",
       "          [3968, 4035, 3973,  ..., 4026, 4029, 4030]]]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 64, 64])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.BatchNorm2d(32)(xx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mks\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ks' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MaxPool2d(kernel_size=pooling_kernel_sizes[0], stride=pooling_strides[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_bn_down = [nn.BatchNorm2d(fs) for fs in down_filter_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_bn_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 64, 128]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_filter_sizes[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_conv_down = [\n",
    "    nn.Conv2d(in_channels=inp_ch, out_channels=fs, kernel_size=ks, padding=pad)\n",
    "    for inp_ch, fs, ks, pad in zip([3]+down_filter_sizes[:-1], down_filter_sizes, kernel_sizes, conv_paddings) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_conv_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_pooling = [nn.MaxPool2d(kernel_size=pks, stride=ps) for pks, ps in zip(pooling_kernel_sizes, pooling_strides)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_down_layers = len(kernel_sizes)\n",
    "num_up_layers = len(kernel_sizes)\n",
    "\n",
    "input_size = 3 # initial number of input channels\n",
    "# Construct downsampling layers.\n",
    "# As mentioned in the assignment, blocks of the downsampling path should have the\n",
    "# following output dimension (igoring batch dimension):\n",
    "# 3 x 64 x 64 (input) -> 32 x 32 x 32 -> 64 x 16 x 16 -> 128 x 8 x 8 -> 256 x 4 x 4\n",
    "# each block should consist of: Conv2d->BatchNorm2d->ReLU->MaxPool2d\n",
    "layers_conv_down = [\n",
    "    nn.Conv2d(in_channels=inp_ch, out_channels=fs, kernel_size=ks, padding=pad)\n",
    "    for inp_ch, fs, ks, pad in zip([input_size]+down_filter_sizes[:-1], down_filter_sizes, kernel_sizes, conv_paddings) \n",
    "]\n",
    "layers_bn_down = [nn.BatchNorm2d(fs) for fs in down_filter_sizes]\n",
    "layers_pooling = [nn.MaxPool2d(kernel_size=pks, stride=ps) for pks, ps in zip(pooling_kernel_sizes, pooling_strides)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Python list to nn.ModuleList, so that PyTorch's autograd\n",
    "# package can track gradients and update parameters of these layers\n",
    "layers_conv_down = nn.ModuleList(layers_conv_down)\n",
    "layers_bn_down = nn.ModuleList(layers_bn_down)\n",
    "layers_pooling = nn.ModuleList(layers_pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in layers_conv_down:\n",
    "    c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 64, 128, 256]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_filter_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128, 64, 32, 32]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_filter_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_conv_up = [\n",
    "    nn.Conv2d(in_channels=inp_ch, out_channels=fs, kernel_size=ks, padding=pad)\n",
    "    for inp_ch, fs, ks, pad in zip(list(reversed(down_filter_sizes)), up_filter_sizes, kernel_sizes, conv_paddings) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_conv_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_bn_up = [nn.BatchNorm2d(fs) for fs in up_filter_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_bn_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 256, 4, 4])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee = torch.randn(32, 256, 4, 4)\n",
    "ee.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MaxUnpool2d.forward() missing 1 required positional argument: 'indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlayers_unpooling\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers_conv_up\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mee\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ex4/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ex4/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: MaxUnpool2d.forward() missing 1 required positional argument: 'indices'"
     ]
    }
   ],
   "source": [
    "layers_unpooling[0](layers_conv_up[0](ee)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct upsampling layers\n",
    "# As mentioned in the assignment, blocks of the upsampling path should have the\n",
    "# following output dimension (igoring batch dimension):\n",
    "# 256 x 4 x 4 (input) -> 128 x 8 x 8 -> 64 x 16 x 16 -> 32 x 32 x 32 -> 32 x 64 x 64\n",
    "# each block should consist of: MaxUnpool2d->Conv2d->BatchNorm2d->ReLU\n",
    "layers_conv_up = [\n",
    "    nn.Conv2d(in_channels=inp_ch, out_channels=fs, kernel_size=ks, padding=pad)\n",
    "    for inp_ch, fs, ks, pad in zip(list(reversed(down_filter_sizes)), up_filter_sizes, kernel_sizes, conv_paddings) \n",
    "]\n",
    "layers_bn_up = [nn.BatchNorm2d(fs) for fs in up_filter_sizes]\n",
    "layers_unpooling = [nn.MaxUnpool2d(kernel_size=pks, stride=ps) for pks, ps in zip(pooling_kernel_sizes, pooling_strides)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0)),\n",
       " MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0)),\n",
       " MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0)),\n",
       " MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_unpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert Python list to nn.ModuleList, so that PyTorch's autograd\n",
    "# can track gradients and update parameters of these layers\n",
    "layers_conv_up = nn.ModuleList(layers_conv_up)\n",
    "layers_bn_up = nn.ModuleList(layers_bn_up)\n",
    "layers_unpooling = nn.ModuleList(layers_unpooling)\n",
    "\n",
    "relu = nn.ReLU(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
